{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6778907,"sourceType":"datasetVersion","datasetId":3901166},{"sourceId":6802780,"sourceType":"datasetVersion","datasetId":3914193},{"sourceId":6940400,"sourceType":"datasetVersion","datasetId":3985781},{"sourceId":6940762,"sourceType":"datasetVersion","datasetId":3985980}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q bitsandbytes datasets accelerate loralib\n!pip install -q git+https://github.com/huggingface/peft.git git+https://github.com/huggingface/transformers.git\n!pip install transformers[sentencepiece]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel, get_peft_model\n\n# Used for multi-gpu\nper_device_train_batch_size = 2#4\n# per_device_eval_batch_size = 4\ngradient_accumulation_steps = 1\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nweight_decay = 0.001\n\nmax_seq_length = None\nlearning_rate = 2e-4\nmax_grad_norm = 0.3\nweight_decay = 0.001\n# The model that you want to train from the Hugging Face hub\nmodel_name = \"openlm-research/open_llama_3b_v2\"\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Activate nested quantization for 4-bit base models\nuse_nested_quant = False\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Number of training epochs\nnum_train_epochs = 5,#4\n\n# Enable fp16 training, (bf16 to True with an A100)\nfp16 = True#False\n\n# Enable bf16 training\nbf16 = False\n\n# Use packing dataset creating\npacking = False\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Optimizer to use, original is paged_adamw_32bit\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule (constant a bit better than cosine, and has advantage for analysis)\nlr_scheduler_type = \"cosine\"\n\n# Number of optimizer update steps, 10K original, 20 for demo purposes\nmax_steps = -1\n\n# Fraction of steps to do a warmup for\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length (saves memory and speeds up training considerably)\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 10\n\n# Log every X updates steps\nlogging_steps = 1\n\n# The output directory where the model predictions and checkpoints will be written\n# output_dir = \"./AHS_OPS_alpha_v_2.0\"\noutput_dir = \"./AHS_OPS-WPCS_ALPHA_V_1.0\"\n\n# Load the entire model on the GPU 0\n# device_map = {\"\": 0}\n\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=use_4bit,\n        bnb_4bit_quant_type=bnb_4bit_quant_type,\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=use_nested_quant,\n    )\n\nmodel = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        device_map=\"auto\",\n        quantization_config=bnb_config\n    )\n\nmodel.config.use_cache = False\n\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\",trust_remote_code=True,use_fast=False,padding=256,truncation=256)#!\ntokenizer.pad_token = \"<p>\"\ntokenizer.padding_side = \"right\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question=\"Where can I find information about the Scheduling Process for Calgary Zone Staffing Service in Health Link Alberta?You can find information about the Scheduling Process for Calgary Zone Staffing Service at\"\nprint(question)\nencodings=tokenizer.encode(question,add_special_tokens=False)\nprint(encodings)\na=[]\nfor i in encodings:\n    a.append(tokenizer.decode(i))\nprint(a)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer\n\n# Replace 'bert-base-uncased' with the appropriate model name for your use case\n\nquestion = \"Where can I find information about the Scheduling Process for Calgary Zone Staffing Service in Health Link Alberta?\"\nprint(question)\n\nencodings = tokenizer.encode(question, add_special_tokens=False)\nprint(\"Token IDs:\", encodings)\n\ntokens = [tokenizer.decode(i) for i in encodings]\nprint(\"Decoded Tokens:\", tokens)\n\n# Create a table comparing tokens and their ids\ndata = {'Token': tokens, 'ID': encodings}\ndf = pd.DataFrame(data)\n\n# Print the table\nprint(\"\\nToken-ID Mapping:\")\npd.set_option('display.max_columns', None)\n# pd.reset_option('display.max_columns')\ndf.T\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n# https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-hiac-update-ops-non-clinical.pdf\n# Add URLs as special tokens\nurls=['https://insite.albertahealthservices.ca/811/Page23570.aspx', 'https://insite.albertahealthservices.ca/811/Page8024.aspx', 'https://insite.albertahealthservices.ca/811/Page7098.aspx', 'https://insite.albertahealthservices.ca/811/Page15109.aspx', 'https://insite.albertahealthservices.ca/811/Page3073.aspx', 'https://insite.albertahealthservices.ca/811/Page5968.aspx', 'https://insite.albertahealthservices.ca/811/Page15134.aspx', 'https://insite.albertahealthservices.ca/811/Page15134.aspx', 'https://insite.albertahealthservices.ca/811/Page5968.aspx', 'https://insite.albertahealthservices.ca/811/Page3073.aspx', 'https://insite.albertahealthservices.ca/811/Page15109.aspx', 'https://insite.albertahealthservices.ca/811/Page7098.aspx', 'https://insite.albertahealthservices.ca/811/Page8024.aspx', 'https://insite.albertahealthservices.ca/811/Page23570.aspx', 'https://insite.albertahealthservices.ca/811/Page6896.aspx', 'https://insite.albertahealthservices.ca/811/Page23570.aspx', 'https://insite.albertahealthservices.ca/811/Page8024.aspx', 'https://insite.albertahealthservices.ca/811/Page8254.aspx.', 'https://insite.albertahealthservices.ca/811/Page7098.aspx', 'https://insite.albertahealthservices.ca/811/Page15109.aspx', 'https://insite.albertahealthservices.ca/811/Page3073.aspx', 'https://insite.albertahealthservices.ca/811/Page5968.aspx', 'https://insite.albertahealthservices.ca/811/Page15134.aspx', 'https://insite.albertahealthservices.ca/811/Page6896.aspx', 'https://insite.albertahealthservices.ca/811/Page6896.aspx', \n'https://insite.albertahealthservices.ca/811/Page7098.aspx', 'https://insite.albertahealthservices.ca/811/Page23570.aspx', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-collection-access-use-disclosure-information.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-transmission-information.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-privacy-protect-ia.pdf', 'https://insite.albertahealthservices.ca/Main/assets/tms/lp/tms-lp-guidelines-safeguarding-security-awareness.pdf', 'https://insite.albertahealthservices.ca/main/assets/tms/lp/tms-lp-privacy-pointer-9.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-it-acceptable-use.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-lync-guidelines.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-guidelines-use-of-mobile-devices-final.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-social-media.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-communications.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-workplace-health-safety.pdf', 'https://insite.albertahealthservices.ca/corporate-policies.asp', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-privacy-protect-ia.pdf', 'https://insite.albertahealthservices.ca/Main/assets/tms/lp/tms-lp-guidelines-safeguarding-security-awareness.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-it-acceptable-use.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-communications.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-guidelines-use-of-mobile-devices-final.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-workplace-health-safety.pdf', 'https://insite.albertahealthservices.ca/Main/assets/tms/lp/tms-lp-guidelines-safeguarding-security-awareness.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-lync-guidelines.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-guidelines-use-of-mobile-devices-final.pdf', 'https://insite.albertahealthservices.ca/corporate-policies.asp', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-collection-access-use-disclosure-information.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-privacy-protect-ia.pdf', 'https://insite.albertahealthservices.ca/Main/assets/tms/lp/tms-lp-guidelines-safeguarding-security-awareness.pdf', 'https://insite.albertahealthservices.ca/main/assets/tms/lp/tms-lp-privacy-pointer-9.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-it-acceptable-use.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-lync-guidelines.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-social-media.pdf', 'https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-workplace-health-safety.pdf', 'https://insite.albertahealthservices.ca/corporate-policies.asp', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-amh-line.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-covid-assistance-team.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-escalation-of-issues-to-hl-leadership-on-call.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-outpatient-covid-treatment-program.pdf', 'https://share.albertahealthservices.ca/teams/PADIS/ManagerOnCallBugOut/SitePages/Home.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-amh-line.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-virtual-md.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-gen-bp-prov-chart-request-management-initial-request.pdf', 'https://insite.albertahealthservices.ca/811/Page15013.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-gen-bp-prov-complaint-commendation-manager.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-education-posting-request.docm', 'https://insite.albertahealthservices.ca/811/Page8254.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-flowchart-build-and-updates-process.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-gen-bp-prov-hia-foip-breach-ccc-sl.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-response-guidelines.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-out-of-office-delegation.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-staff-privacy-breach-investigation-process.pdf', 'https://share.albertahealthservices.ca/teams/HLA/moc', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-manager-on-call-virtual-code-white.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-orientation-booking-request-calgary.docm', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-orientation-booking-request-edmonton.docm', 'http://tableau.albertahealthservices.ca/#/views/HealthLink-Current1_0/HealthLink-RealTime?:refresh=yes', 'https://insite.albertahealthservices.ca/811/Page3073.aspx', 'https://insite.albertahealthservices.ca/811/Page8788.aspx', 'https://insite.albertahealthservices.ca/811/Page24554.aspx', 'https://insite.albertahealthservices.ca/811/Page12564.aspx', 'https://insite.albertahealthservices.ca/811/Page7095.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-activate-ain.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-frequently-used-numbers.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-moc-tether-iphone-laptop.pdf', 'https://insite.albertahealthservices.ca/811/Page8254.aspx', 'https://insite.albertahealthservices.ca/811/Page7242.aspx', 'https://insite.albertahealthservices.ca/811/Page7244.aspx', 'https://insite.albertahealthservices.ca/hla/tms-hla-moc-emerging-events-checklist.doc', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-moc-emerging-events-uncomplicated.pdf', 'https://insite.albertahealthservices.ca/assets/et/untei/et-untei-report.docx', 'http://www.myhealth.alberta.ca/', 'https://www.albertahealthservices.ca/topics/Page18168.aspx', 'https://insite.albertahealthservices.ca/811/Page24493.aspx', 'https://insite.albertahealthservices.ca/811/Page24499.aspx', 'https://insite.albertahealthservices.ca/811/Page24501.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/AppSupport/tms-811-as-who-to-call-tech-support-calgary.pdf', 'https://ca1.unifier.oraclecloud.com/ahs/portal', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/AppSupport/tms-811-as-who-to-call-tech-support-edmonton.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-gen-bp-prov-ia-afterhours-outage.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Flowcharts/tms-811-gen-bp-prov-ia-business-hours-outage.pdfs', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-ia-after-hours-unplanned-outage-notification.docm', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-ia-business-hours-unplanned-outage-notification.docm', 'http://www.albertahealthservices.ca/topics/Page16944.aspx', 'https://insite.albertahealthservices.ca/811/Page24484.aspx#doc-update', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-vaccine-escalation-homebound.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-vaccine-escalation-low-stimulus-clinic-setting.pdf', 'http://share.ahsnet.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-vaccine-issue-documentation.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/VBL/tms-811-vbl-covid-immunization-record-request-form.pdf', 'https://insite.albertahealthservices.ca/811/Page24685.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-immunization-public-booking-guide.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-19-vaccine-booking-call-center-escalation-guide.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-19-ppe-job-aid.pdf', 'https://insite.albertahealthservices.ca/811/Page24685.aspx', 'https://insite.albertahealthservices.ca/811/Page24685.aspx#testing-protocols', 'https://insite.albertahealthservices.ca/811/Page24685.aspx#work-instruction-docs', 'https://insite.albertahealthservices.ca/811/Page24493.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-19-vaccine-booking-call-center-escalation-guide.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Emerging%20Events/tms-811-covid-19-ppe-job-aid.pdf', 'https://insite.albertahealthservices.ca/811/Page24685.aspx', 'https://insite.albertahealthservices.ca/811/Page24685.aspx#work-instruction-docs', 'https://myhealth.alberta.ca/health/Pages/default.aspx', 'https://myhealth.alberta.ca/learning/modules/insulin-pump-therapy', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-mha-search-tips.pdf', 'https://myhealth.alberta.ca/health/Pages/HealthVideoPlayer.aspx', 'https://myhealth.alberta.ca/Pages/news2.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-mha-phr-faq.pdf', 'https://myhealth.alberta.ca/Pages/news2.aspx', 'https://tableau.albertahealthservices.ca/#/workbooks/29497/views', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-report-monthly.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-report-quarterly-southzone.pdf.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-report-activity.pdf.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-report-annual.pdf.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-report-annual-albertaquits.pdf.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-qm-nsg-documenting-evaluation.pdf', 'https://redcap.albertahealthservices.ca/surveys/?s=DR7T4CNHP3NH3478.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-nursing-coaching-corner-choosing-a-guideline.pdf.', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-qm-coaching-corner-virtual-md.pdf.', 'https://www.albertahealthservices.ca/info/page10904.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-calgary-zone-staffing-service-process.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-quick-reference-guide-phase-1-employee-cz.pdf', 'https://www.albertahealthservices.ca/tools/is/Page7024.aspx', 'https://www.albertahealthservices.ca/hr/Page2589.aspx', 'https://www.albertahealthservices.ca/hr/Page4724.aspx', 'https://www.albertahealthservices.ca/hr/Page845.aspx', 'https://share.albertahealthservices.ca/main/assets/hr/tms-hr-whs-health-and-wellness-action-plan.pdf', 'https://share.albertahealthservices.ca/hr/Page964.aspx', 'https://edm/Page3035.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-cal-whs-first-aid-plan.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-harassment-violence-prevention-plan.pdf', 'https://insite.albertahealthservices.ca/hr/Page11933.aspx', 'https://insite.albertahealthservices.ca/hr/Page5862.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-psychological-health-and-safety-resources.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-psychosocial-risk-factor.pdf', 'https://insite.albertahealthservices.ca/hr/Page3432.aspx', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-hiac-update-clinical.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-hiac-update-ops-non-clinical.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-hiac-update-manager.pdf', 'https://share.albertahealthservices.ca/teams/HLA/Webdocs/Operations/tms-811-op-hiac-update_director.pdf', \n'https://share.albertahealthservices.ca/main/assets/hr/tms-hr-whs-scent-awareness-guiding-practice.pdf', 'https://www.wcb.ab.ca/assets/pdfs/public/office_ergo.pdf']\nemails_no=['780-701-7281', '780-289-5923', '403-910-3767', '403-926-4728', '587-772-2741', '780-774-8331', '780-809-0657', '780-809-2407', '587-779-4063', '403-462-3798', \n           '403-910-4322', '403-837-0837', '587-774-8284', '403-804-6215', '780-306-1218', '587-566-5671', '000-000-0000', '780-306-2704', '587-774-5119', '587-585-4518', \n           '306-535-2582', '587-774-4498', '403-903-9040', '587-773-1220', '780-809-3377', '780-306-2183', '587-773-2649', '587-689-4037', '587-773-1523', \n           'gurpreet.rai@albertahealthservices.ca', 'samantha.matanda@albertahealthservices.ca', 'alexandre.terekhov@albertahealthservices.ca', \n           'allex.kwang@albertahealthservices.ca', 'amir.haroun@albertahealthservices.ca', 'darryl.becker@albertahealthservices.ca', 'davids.larsen@albertahealthservices.ca',\n           'dorsa.azimi@albertahealthservices.ca', 'tino.tran@albertahealthservices.ca', 'tino.tran@albertahealthservices.ca', 'edward.remedios@albertahealthservices.ca', \n           'epic.defarrin@albertahealthservices.ca', 'farid.mobasseri@albertahealthservices.ca', 'gurnoor.sekhon@albertahealthservices.ca', \n           'haider.khan@albertahealthservices.ca', 'hirak.patel@albertahealthservices.ca', 'ibukunoluwa.alao@albertahealthservices.ca', 'jalen.shannon@albertahealthservices.ca', \n           'john.to@albertahealthservices.ca', 'julie.clarkson@albertahealthservices.ca', 'louie.villa@albertahealthservices.ca', 'maulesh.mistry@albertahealthservices.ca', \n           'mustafa.kilic@albertahealthservices.ca', 'natnael.beshawered@albertahealthservices.ca', 'parisa.ghanbari@albertahealthservices.ca',\n           'patricia.limcangco@albertahealthservices.ca', 'pavansai.konduru@albertahealthservices.ca', 'soruban.sivagnanam@albertahealthservices.ca', \n           'yiyu.ren@albertahealthservices.ca', 'sungheum.cho@albertahealthservices.ca', 'sungheum.cho@albertahealthservices.ca', 'suzanne.ly@albertahealthservices.ca', \n           'tatva.joshi@albertahealthservices.ca', 'zaarif.sardar@albertahealthservices.ca', 'zaarif.sardar@albertahealthservices.ca', 'wojciech.marczyk@albertahealthservices.ca',\n           'wojciechmarczyk02@albertahealthservices.ca', 'pooja.tandon@albertahealthservices.ca', 'ping-hong.liu@albertahealthservices.ca', 'matthew.pham@albertahealthservices.ca']\n\ntokenizer.add_special_tokens({\"additional_special_tokens\": urls+emails_no})\n# tokenizer.add_tokens(urls)\n# # Encode text with URLs as single tokens\n# text = \"the official website of the AHS Plaza is https://insite.albertahealthservices.ca/811/Page23570.aspx\"\n# # demo=\"It doesn't apply any text normalization to the URL. Normalization usually involves making text uniform, like converting all letters to lowercase.\"\n\n# for i in tokenizer.encode(text,add_special_tokens = True):\n#     print(tokenizer.decode(i))\n# # Decode the encoded input\n# tokenizer.decode(encoded_input)\n\n# tokenizer.tokenize(text)\n\n# print(tokenizer)\n\nmodel.resize_token_embeddings(len(tokenizer))\n# print(model)\n# !pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer.encode( f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n# ### Instruction:\n# data_point[\"Instruction\"]\n# ### Response:\n# data_point[\"Answer\"] \"\"\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom datasets import Dataset\ntrain = pd.read_csv('/kaggle/input/ahs-ops/AHS_OPS_DATASET_MODIFIED_NEW_V_1.0.csv',encoding='cp1252')#,encoding='cp1252'\n\ndef generate_prompt(data_point):\n    return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n### Instruction=>\n{data_point[\"Instruction\"]}\n### Response=>\n{data_point[\"Answer\"]} {tokenizer.eos_token}\"\"\"\n\ntrain[\"text\"]=train.apply(generate_prompt,axis=1)\n# def encode(sample):\n#     encoded = tokenizer.encode_plus(sample[\"text\"], \n#                                     truncation=True, \n#                                     padding=\"do_not_pad\", \n#                                     return_tensors=\"pt\")\n#     return {\n#         \"input_ids\": encoded[\"input_ids\"].flatten(),\n#         \"attention_mask\": encoded[\"attention_mask\"].flatten()\n#     }\ndataset = Dataset.from_pandas(train)\n# tokenized_dataset = dataset.map(encode)\n\n# dataset=dataset.map(lambda samples: tokenizer(generate_prompt(samples)))\n# dataset_tokenized = dataset_tokenized.map(remove_columns=list([\"Instruction\",\"Answer\"]))\n\n# tokenizer.decode(dataset_tokenized[10][\"input_ids\"])\n# print(dataset[0])\n\n# print(tokenizer.tokenize(\"You can access the 'AHS Social Media Acceptable Use Policy' [here](https://extranet.ahsnet.ca/teams/policydocuments/1/clp-ahs-pol-social-media.pdf).\"))\n\n\n\n# !pip install trl\n\n# !pip install wandb\n\nprint(type(dataset))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"text\"], truncation=True)\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(element):\n            outputs = tokenizer(\n                element[\"text\"],\n                truncation=True,\n                padding=False,\n                max_length=256,\n                return_overflowing_tokens=False,\n                return_length=False,\n            )\n\n\n\n            return {\"input_ids\": outputs[\"input_ids\"], \"attention_mask\": outputs[\"attention_mask\"]}","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(\n            tokenize,\n            batched=True,\n            remove_columns=dataset.column_names,\n#             num_proc=self.dataset_num_proc,\n            batch_size=12,\n        )","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset[0]","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport warnings\nfrom collections import deque\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Optional, Tuple, Union\n\nimport numpy as np\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import IterableDataset\nfrom transformers import DataCollatorForLanguageModeling, PreTrainedModel, PreTrainedTokenizerBase, TrainerCallback\nclass ConstantLengthDataset(IterableDataset):\n    \"\"\"\n    Iterable dataset that returns constant length chunks of tokens from stream of text files.\n    The dataset also formats the text before tokenization with a specific format that is provided\n    by the user.\n\n        Args:\n            tokenizer (`transformers.PreTrainedTokenizer`):\n                The processor used for processing the data.\n            dataset (`dataset.Dataset`):\n                Dataset with text files.\n            dataset_text_field (`str`, **optional**):\n                Name of the field in the dataset that contains the text. Used only if `formatting_func` is `None`.\n            formatting_func (`Callable`, **optional**):\n                Function that formats the text before tokenization. Usually it is recommended to have follows a certain\n                pattern such as `\"### Question: {question}\\n ### Answer: {answer}\\n\"`\n            infinite (`bool`, *optional*, defaults to `False`):\n                If True the iterator is reset after dataset reaches end else stops.\n            seq_length (`int`, *optional*, defaults to `1024`):\n                Length of token sequences to return.\n            num_of_sequences (`int`, *optional*, defaults to `1024`):\n                Number of token sequences to keep in buffer.\n            chars_per_token (`int`, *optional*, defaults to `3.6`):\n                Number of characters per token used to estimate number of tokens in text buffer.\n            eos_token_id (`int`, *optional*, defaults to `0`):\n                Id of the end of sequence token if the passed tokenizer does not have an EOS token.\n            shuffle ('bool', *optional*, defaults to True)\n                Shuffle the examples before they are returned\n    \"\"\"\n\n    def __init__(\n        self,\n        tokenizer,\n        dataset,\n        dataset_text_field=None,\n        formatting_func=None,\n        infinite=False,\n        seq_length=1024,\n        num_of_sequences=1024,\n        chars_per_token=3.6,\n        eos_token_id=0,\n        shuffle=True,\n    ):\n        self.tokenizer = tokenizer\n\n        if tokenizer.eos_token_id is None:\n            warnings.warn(\n                \"The passed tokenizer does not have an EOS token. We will use the passed eos_token_id instead which corresponds\"\n                f\" to {eos_token_id}. If this is not the correct EOS token, make sure to pass the correct eos_token_id.\"\n            )\n\n        self.concat_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id else eos_token_id\n        self.dataset = dataset\n        self.seq_length = seq_length\n        self.infinite = infinite\n        self.current_size = 0\n        self.max_buffer_size = seq_length * chars_per_token * num_of_sequences\n        self.shuffle = shuffle\n        if formatting_func is None:\n            self.formatting_func = lambda x: x[dataset_text_field]\n        else:\n            self.formatting_func = formatting_func\n\n        if formatting_func is not None:\n            formatting_func_signature = formatting_func.__code__.co_varnames\n            if len(formatting_func_signature) > 1:\n                warnings.warn(\n                    \"The passed formatting_func has more than one argument. Usually that function should have a single argument `example`\"\n                    \" which corresponds to the dictionary returned by each element of the dataset. Make sure you know what you are doing.\"\n                )\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __iter__(self):\n        iterator = iter(self.dataset)\n        more_examples = True\n        while more_examples:\n            buffer, buffer_len = [], 0\n            while True:\n                if buffer_len >= self.max_buffer_size:\n                    break\n                try:\n                    buffer.append(self.formatting_func(next(iterator)))\n                    buffer_len += len(buffer[-1])\n                except StopIteration:\n                    if self.infinite:\n                        iterator = iter(self.dataset)\n                        warnings.warn(\"The dataset reached end and the iterator is reset to the start.\")\n                    else:\n                        more_examples = False\n                        break\n            tokenized_inputs = self.tokenizer(buffer, truncation=False)[\"input_ids\"]\n            all_token_ids = []\n            for tokenized_input in tokenized_inputs:\n                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n            examples = []\n            for i in range(0, len(all_token_ids), self.seq_length):\n                input_ids = all_token_ids[i : i + self.seq_length]\n                if len(input_ids) == self.seq_length:\n                    examples.append(input_ids)\n            if self.shuffle:\n                random.shuffle(examples)\n            for example in examples:\n                self.current_size += 1\n                yield {\n                    \"input_ids\": torch.LongTensor(example),\n                    \"labels\": torch.LongTensor(example),\n                }\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install utils\n# from utils import ConstantLengthDataset\n    \ndata=ConstantLengthDataset(\n                tokenizer,\n                dataset_new,\n                dataset_text_field=\"text\",\n#                 formatting_func=formatting_func,\n                seq_length=256,\n#                 infinite=infinite,\n                num_of_sequences=256,\n                chars_per_token=3.6,\n                eos_token_id=tokenizer.eos_token_id,\n            )\nfor i in data:\n    print(i)\n    break","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(dataset)\nfrom torch.utils.data import Dataset\n \nclass HFDataset(Dataset):\n    def __init__(self, dset):\n        self.dset = dset\n\n    def __getitem__(self, idx):\n        return self.dset[idx]\n\n    def __len__(self):\n        return len(self.dset)\n\ndataset_new = HFDataset(tokenized_datasets)\nlen(dataset_new[1][\"input_ids\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_new[0]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isinstance(dataset_new, torch.utils.data.Dataset)\n# dataset is not None\n#     545     and isinstance(train_dataset, torch.utils.data.IterableDataset)\n#     546     and args.group_by_length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install trl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer\nfrom transformers import DataCollatorForLanguageModeling\n\nconfig = LoraConfig(\n    r=8,#real=16\n    lora_alpha=16,#real=64\n    target_modules=['base_layer','gate_proj', 'v_proj','up_proj','down_proj','q_proj','k_proj','o_proj'],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=5,#10 for best results\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=fp16,\n    bf16=bf16,\n    # max_grad_norm=max_grad_norm,\n#     max_steps=50,\n    num_train_epochs=1,#10 for ops dataset with 311 rows of data and 12/10 batch size.\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n#     evaluation_strategy=\"steps\",\n#     report_to=\"wandb\",\n#     push_to_hub=True,\n#     hub_token =\"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\",\n#     auto_find_batch_size =True\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset_new,\n#     eval_dataset=dataset,\n    peft_config=config,\n    dataset_text_field=\"text\",\n    max_seq_length=256,\n    tokenizer=tokenizer,\n    args=training_arguments,\n#     packing=True,\n    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/results/\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:22:15.241812Z","iopub.execute_input":"2023-11-20T20:22:15.242502Z","iopub.status.idle":"2023-11-20T20:22:15.407023Z","shell.execute_reply.started":"2023-11-20T20:22:15.242469Z","shell.execute_reply":"2023-11-20T20:22:15.405950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = os.path.join(\"/kaggle/working/results/\", \"final_checkpoint\")\ntrainer.model.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:22:59.063263Z","iopub.execute_input":"2023-11-20T20:22:59.064057Z","iopub.status.idle":"2023-11-20T20:22:59.222223Z","shell.execute_reply.started":"2023-11-20T20:22:59.064021Z","shell.execute_reply":"2023-11-20T20:22:59.221054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}