{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GGUF FILE LINK: https://huggingface.co/Tatvajsh/AHS_OPS_GGUF_V_1.0"
      ],
      "metadata": {
        "id": "FAECEtAWetzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain ctransformers sentence-transformers faiss-gpu faiss-cpu"
      ],
      "metadata": {
        "id": "AbpkwTKFv4G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir\n"
      ],
      "metadata": {
        "id": "jQ_oqM8sZgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader,DirectoryLoader,TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import LlamaCppEmbeddings\n",
        "\n",
        "DATA_PATH=\"/content/data\"\n",
        "DB_FAISS_PATH=\"/content/vectorstores/db_faiss\"\n",
        "\n",
        "def create_vector_db():\n",
        "    #Create a DirectoryLoader to load all PDFs from the DATA_PATH. Use the PyPDFLoader to load each PDF.\n",
        "    loader=DirectoryLoader(DATA_PATH,glob=\"*.txt\",loader_cls=TextLoader)\n",
        "    documents=loader.load()\n",
        "    #shared overlapping text gives some continuity between chunks and context.\n",
        "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=80)\n",
        "    # text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=150)\n",
        "\n",
        "    texts=text_splitter.split_documents(documents)# all the splitted text is here,text chunks\n",
        "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                     model_kwargs={'device':'cuda'})#creating the embeddings\n",
        "    db=FAISS.from_documents(texts,embeddings)#using this embedding model,create all the embedding and store it\n",
        "    db.save_local(DB_FAISS_PATH)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "        create_vector_db()"
      ],
      "metadata": {
        "id": "qggIubKnZ2UA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama\n",
        "from langchain import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.chains import RetrievalQA\n",
        "llm = Llama(model_path=\"/content/drive/MyDrive/ggml-model-q8_0.gguf\",n_gpu_layers=100)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       model_kwargs={'device': 'cuda'})\n",
        "DB_FAISS_PATH = '/content/vectorstores/db_faiss'\n",
        "db = FAISS.load_local(DB_FAISS_PATH, embeddings)\n",
        "\n",
        "# for out in output:\n",
        "#     completionfragement=copy.deepcopy(out)\n",
        "#     print(completionfragement[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvaHPlJgwXuu",
        "outputId": "b5433f6a-7238-4320-e822-3972f1581e2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"What resources are available for the MOC Outpatient COVID Treatment Program?\"\n",
        "docs = db.similarity_search(question,k=1)\n",
        "context_list=[]\n",
        "for i in docs:\n",
        "    context_list.append(i.page_content)\n",
        "context=\"\\n\".join(context_list)\n",
        "# print(context)\n",
        "prompt=f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request from the given context\n",
        "    ### Instruction:\n",
        "    {question}\n",
        "    ### Context:\n",
        "    {context}\n",
        "    ### Response:\n",
        "    \"\"\"\n",
        "output = llm(prompt, max_tokens=1024,temperature=0.10, stop=[\"</s>\"], echo=True)\n",
        "# print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6AqL7IT0hL5",
        "outputId": "3eba3c22-e57b-43c9-b56a-07a174a6a041"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[\"choices\"][0][\"text\"].split(\"Response:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJaKOlaAIF01",
        "outputId": "7add8885-49f3-4a74-f6ba-255ae24d286d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    The following resources are available for COVID treatment program at Alberta Health Services (AHS) MOC Outpatient Clinic in Edmonton, AB Canada:<br>\n",
            "    <ul>\n",
            "        <li>10 beds</li>\n",
            "        <li>24/7 coverage by a physician and nurse practitioner</li>\n",
            "        <li>Patients are seen on an appointment basis only.</li>\n",
            "        <li>Patients must be referred to the clinic from their family physician or other health care provider. Patients can self-refer if they have been diagnosed with COVID-19, but will need a referral from their primary care provider before being seen at MOC Outpatient Clinic</li>\n",
            "        <li>Patients are not able to be admitted directly into the clinic.</li>\n",
            "        <li>Patients must be medically stable and able to travel to Edmonton for treatment. Patients who require admission to the hospital will be referred to the appropriate facility.</li>\n",
            "        <li>Patients with a fever of 38C or higher, cough, shortness of breath, or other respiratory symptoms should not come to MOC Outpatient Clinic</li>\n",
            "        <li>Patients must have a negative COVID-19 test result within the last 72 hours before their appointment. Patients who are unable to provide a negative COVID-19 test result will be referred back to their primary care provider for testing.</li>\n",
            "        <li>Patients with suspected COVID-19 should not come to MOC Outpatient Clinic</li>\n",
            "        <li>Patients must have a valid Alberta Health Care card\n"
          ]
        }
      ]
    }
  ]
}